{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5aae554-143f-4a01-9303-6f2af907616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e5cf4e-02d4-485b-a473-66a30abe94fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "\n",
       "  Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0   Salaried  Female                       3                3.0   \n",
       "1   Salaried    Male                       3                4.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0        Single            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Travel.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900c33a9-fdf1-467c-9ae0-3b0049942d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70de060-6224-4669-9f8f-ebcefb410baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                    int64\n",
       "ProdTaken                     int64\n",
       "Age                         float64\n",
       "TypeofContact                object\n",
       "CityTier                      int64\n",
       "DurationOfPitch             float64\n",
       "Occupation                   object\n",
       "Gender                       object\n",
       "NumberOfPersonVisiting        int64\n",
       "NumberOfFollowups           float64\n",
       "ProductPitched               object\n",
       "PreferredPropertyStar       float64\n",
       "MaritalStatus                object\n",
       "NumberOfTrips               float64\n",
       "Passport                      int64\n",
       "PitchSatisfactionScore        int64\n",
       "OwnCar                        int64\n",
       "NumberOfChildrenVisiting    float64\n",
       "Designation                  object\n",
       "MonthlyIncome               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f325222-8cf2-4219-8f60-47ab01c10180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                    0\n",
       "ProdTaken                     0\n",
       "Age                         226\n",
       "TypeofContact                25\n",
       "CityTier                      0\n",
       "DurationOfPitch             251\n",
       "Occupation                    0\n",
       "Gender                        0\n",
       "NumberOfPersonVisiting        0\n",
       "NumberOfFollowups            45\n",
       "ProductPitched                0\n",
       "PreferredPropertyStar        26\n",
       "MaritalStatus                 0\n",
       "NumberOfTrips               140\n",
       "Passport                      0\n",
       "PitchSatisfactionScore        0\n",
       "OwnCar                        0\n",
       "NumberOfChildrenVisiting     66\n",
       "Designation                   0\n",
       "MonthlyIncome               233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd079b9-128d-44a8-9975-f8a73adaa6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for column 'TypeofContact':\n",
      "TypeofContact\n",
      "Self Enquiry       3444\n",
      "Company Invited    1419\n",
      "NaN                  25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for column 'Occupation':\n",
      "Occupation\n",
      "Salaried          2368\n",
      "Small Business    2084\n",
      "Large Business     434\n",
      "Free Lancer          2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for column 'Gender':\n",
      "Gender\n",
      "Male       2916\n",
      "Female     1817\n",
      "Fe Male     155\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for column 'ProductPitched':\n",
      "ProductPitched\n",
      "Basic           1842\n",
      "Deluxe          1732\n",
      "Standard         742\n",
      "Super Deluxe     342\n",
      "King             230\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for column 'MaritalStatus':\n",
      "MaritalStatus\n",
      "Married      2340\n",
      "Divorced      950\n",
      "Single        916\n",
      "Unmarried     682\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for column 'Designation':\n",
      "Designation\n",
      "Executive         1842\n",
      "Manager           1732\n",
      "Senior Manager     742\n",
      "AVP                342\n",
      "VP                 230\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over columns and print value counts for object type columns\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"Value counts for column '{column}':\")\n",
    "    print(df[column].value_counts(dropna=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddbc2fac-f3da-41c0-8a42-6119112d56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].replace('Fe Male', 'Female')\n",
    "df['MaritalStatus'] = df['MaritalStatus'].replace('Single', 'Unmarried')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b9dfbf-cadc-4643-bb9c-d69c7cdad8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nage\\AppData\\Local\\Temp\\ipykernel_16568\\3927510868.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.Age.fillna(df.Age.median(), inplace=True)\n",
      "C:\\Users\\nage\\AppData\\Local\\Temp\\ipykernel_16568\\3927510868.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.TypeofContact.fillna(df.TypeofContact.mode()[0], inplace=True)\n",
      "C:\\Users\\nage\\AppData\\Local\\Temp\\ipykernel_16568\\3927510868.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.DurationOfPitch.fillna(df.DurationOfPitch.median(), inplace=True)\n",
      "C:\\Users\\nage\\AppData\\Local\\Temp\\ipykernel_16568\\3927510868.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfFollowups.fillna(df.NumberOfFollowups.mode()[0], inplace=True)\n",
      "C:\\Users\\nage\\AppData\\Local\\Temp\\ipykernel_16568\\3927510868.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.mode()[0], inplace=True)\n",
      "C:\\Users\\nage\\AppData\\Local\\Temp\\ipykernel_16568\\3927510868.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfTrips.fillna(df.NumberOfTrips.median(), inplace=True)\n",
      "C:\\Users\\nage\\AppData\\Local\\Temp\\ipykernel_16568\\3927510868.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.mode()[0], inplace=True)\n",
      "C:\\Users\\nage\\AppData\\Local\\Temp\\ipykernel_16568\\3927510868.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.MonthlyIncome.fillna(df.MonthlyIncome.median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Age\n",
    "df.Age.fillna(df.Age.median(), inplace=True)\n",
    "\n",
    "#TypeofContract\n",
    "df.TypeofContact.fillna(df.TypeofContact.mode()[0], inplace=True)\n",
    "\n",
    "#DurationOfPitch\n",
    "df.DurationOfPitch.fillna(df.DurationOfPitch.median(), inplace=True)\n",
    "\n",
    "#NumberOfFollowups\n",
    "df.NumberOfFollowups.fillna(df.NumberOfFollowups.mode()[0], inplace=True)\n",
    "\n",
    "#PreferredPropertyStar\n",
    "df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.mode()[0], inplace=True)\n",
    "\n",
    "#NumberOfTrips\n",
    "df.NumberOfTrips.fillna(df.NumberOfTrips.median(), inplace=True)\n",
    "\n",
    "#NumberOfChildrenVisiting\n",
    "df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.mode()[0], inplace=True)\n",
    "\n",
    "#MonthlyIncome\n",
    "df.MonthlyIncome.fillna(df.MonthlyIncome.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e116587a-0cfc-4a4e-a7d8-0c094d17eef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                  0\n",
       "ProdTaken                   0\n",
       "Age                         0\n",
       "TypeofContact               0\n",
       "CityTier                    0\n",
       "DurationOfPitch             0\n",
       "Occupation                  0\n",
       "Gender                      0\n",
       "NumberOfPersonVisiting      0\n",
       "NumberOfFollowups           0\n",
       "ProductPitched              0\n",
       "PreferredPropertyStar       0\n",
       "MaritalStatus               0\n",
       "NumberOfTrips               0\n",
       "Passport                    0\n",
       "PitchSatisfactionScore      0\n",
       "OwnCar                      0\n",
       "NumberOfChildrenVisiting    0\n",
       "Designation                 0\n",
       "MonthlyIncome               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb2ad312-ba58-49fe-b30f-60b2d787e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column for feature\n",
    "df['TotalVisiting'] = df['NumberOfPersonVisiting'] + df['NumberOfChildrenVisiting']\n",
    "df.drop(columns=['NumberOfPersonVisiting', 'NumberOfChildrenVisiting'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5088b90d-a285-4c59-8af5-2d667d0d9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ProdTaken'], axis=1)\n",
    "y = df['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71584401-32ab-4ae7-baaa-57f1ec79d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fe5d4bd-2122-41a0-943a-2585a403e5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3910, 18), (978, 18))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "309b976b-8b55-48fd-b693-82cb4ad0afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "         (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "          (\"StandardScaler\", numeric_transformer, num_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24e25dd6-c450-45cc-9d4a-57c396b7b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "## applying Trnsformation in training(fit_transform)\n",
    "X_train=preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a389f6-ec5f-44f1-bed5-c61b148bbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply tansformation on test(transform)\n",
    "X_test=preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df5e7348-4f98-40a4-bef3-06c70758c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29e7b912-ec1f-4676-9353-b2365c0fd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b0ac0e1-7499-4db6-8ca8-7f96dc23c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8468\n",
      "- F1 score: 0.8214\n",
      "- Precision: 0.7044\n",
      "- Recall: 0.3073\n",
      "- Roc Auc Score: 0.6389\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8354\n",
      "- F1 score: 0.8086\n",
      "- Precision: 0.6786\n",
      "- Recall: 0.2984\n",
      "- Roc Auc Score: 0.6321\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8906\n",
      "- F1 score: 0.8898\n",
      "- Precision: 0.7283\n",
      "- Recall: 0.7016\n",
      "- Roc Auc Score: 0.8190\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9997\n",
      "- F1 score: 0.9997\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9986\n",
      "- Roc Auc Score: 0.9993\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9162\n",
      "- F1 score: 0.9083\n",
      "- Precision: 0.9580\n",
      "- Recall: 0.5969\n",
      "- Roc Auc Score: 0.7953\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Logisitic Regression\":LogisticRegression(),\n",
    "    \"Decision Tree\":DecisionTreeClassifier(),\n",
    "    \"Random Forest\":RandomForestClassifier()\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "    model_train_rocauc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "    model_test_rocauc_score = roc_auc_score(y_test, y_test_pred) #Calculate Roc\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c82b0beb-0c5f-4324-9b2c-37f1bb8eea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter Training\n",
    "rf_params = {\"max_depth\": [5, 8, 15, None, 10],\n",
    "             \"max_features\": [5, 7, \"auto\", 8],\n",
    "             \"min_samples_split\": [2, 8, 15, 20],\n",
    "             \"n_estimators\": [100, 200, 500, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b120177c-8b81-444f-b0e9-db7365382984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models list for Hyperparameter tuning\n",
    "randomcv_models = [\n",
    "                   (\"RF\", RandomForestClassifier(), rf_params)\n",
    "                   \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7118916-9854-45a8-9cc6-d0ee64fbe930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "72 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "37 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "C:\\Users\\nage\\develop\\random forest\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.88388758        nan 0.86649772 0.87979603 0.84475773 0.86061543\n",
      " 0.88516649 0.85371025        nan 0.86445018 0.88644559 0.90025574\n",
      " 0.87851713 0.87289047 0.86700837        nan        nan 0.85371025\n",
      "        nan 0.88107494 0.86445135 0.84706011 0.88695683 0.87289106\n",
      "        nan        nan 0.87263406 0.85140827        nan 0.87493683\n",
      "        nan 0.87544788        nan        nan 0.86879813        nan\n",
      " 0.84578101        nan 0.88491126 0.87084469        nan 0.84475773\n",
      " 0.86163792 0.86879872 0.86982122        nan 0.86087105 0.85140807\n",
      "        nan 0.85243174 0.85396588 0.85243135 0.86777525 0.85294279\n",
      " 0.87544768 0.87161196 0.86956559 0.87212281 0.88593355 0.87186719\n",
      " 0.85064139 0.8708443  0.86879853        nan        nan 0.8744246\n",
      "        nan 0.86879794 0.87110071 0.85191971 0.89565177 0.86956618\n",
      " 0.87519186 0.87058907 0.8708445  0.84603683 0.87186758 0.89744211\n",
      " 0.90051137 0.8682861  0.86803185 0.88260868 0.89565216 0.88311973\n",
      "        nan        nan 0.8542215  0.86470639 0.87928479 0.86317225\n",
      "        nan 0.87826112 0.86726478 0.89820938 0.89974449 0.88312071\n",
      "        nan 0.85396588        nan 0.86982122]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Best Params for RF -------------------\n",
      "{'n_estimators': 500, 'min_samples_split': 2, 'max_features': 7, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   n_jobs=-1)\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2ccc4ca-8e7c-4bc6-9ea1-cd5dc1628722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9254\n",
      "- F1 score: 0.9192\n",
      "- Precision: 0.9683\n",
      "- Recall: 0.6387\n",
      "- Roc Auc Score: 0.8168\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, min_samples_split=2,\n",
    "                                          max_features=7,max_depth=None)\n",
    "model.fit(X_train, y_train) # Train model\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "model_train_rocauc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "# Test set performance\n",
    "model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "model_test_rocauc_score = roc_auc_score(y_test, y_test_pred) #Calculate Roc\n",
    "\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "\n",
    "print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b95a9ef-9e18-4932-9119-b81c530ebb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f94a79cd-d56c-40c4-9f7e-6db0fd8e9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ColumnTransformer to a pickle file\n",
    "with open('preprocessor.pkl', 'wb') as file:\n",
    "    pickle.dump(preprocessor, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab73aba4-cb47-4a0e-9b1f-f81c6ed0c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ColumnTransformer to a pickle file\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6944dc-0ecc-4bab-9493-1924ecf2093d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bagging implementation for both regression and classification\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Check if the task is regression or classification\n",
    "is_classification = 'target_variable_class' in data.columns  # Example column name\n",
    "\n",
    "# Train-Test split (replace with your data splitting logic)\n",
    "X = data.drop(columns=['target_variable'])  # Features (replace 'target_variable' with the correct column name)\n",
    "y = data['target_variable']  # Target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "if is_classification:\n",
    "    # Bagging for classification\n",
    "    base_model = DecisionTreeClassifier()  # Base learner\n",
    "    bagging_model = BaggingClassifier(base_estimator=base_model, n_estimators=10, random_state=42)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    predictions = bagging_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Bagging Classification Accuracy: {accuracy:.2f}\")\n",
    "else:\n",
    "    # Bagging for regression\n",
    "    base_model = DecisionTreeRegressor()  # Base learner\n",
    "    bagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    predictions = bagging_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"Bagging Regression MSE: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79e707-b01e-432b-8d96-bf721ffbd06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, VotingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Define individual models\n",
    "model1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "model2 = SVC(probability=True, random_state=42)  # Example of another model\n",
    "model3 = LogisticRegression(random_state=42)\n",
    "\n",
    "# Combine models using VotingClassifier for classification tasks\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('bagging_dt', model1), \n",
    "        ('svc', model2), \n",
    "        ('logreg', model3)\n",
    "    ],\n",
    "    voting='soft'  # Use 'soft' for probability averaging or 'hard' for majority voting\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = ensemble_model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
